# Bun Native Fetch API Demo
# Demonstrates high-performance HTTP requests with Bun's native fetch

# Async fetch examples
async def fetch_example():
    print("üåê Bun Native Fetch API Demo")
    print("=" * 50)

    # Example 1: Simple GET request
    print("\n‚ú® Example 1: Simple GET Request")
    try:
        response = await fetch("https://api.github.com/users/github")
        if response.ok:
            data = await response.json()
            print(f"   User: {data['login']}")
            print(f"   Name: {data['name']}")
            print(f"   Public Repos: {data['public_repos']}")
            print("   ‚úì Success with Bun's native fetch!")
        else:
            print(f"   Error: {response.status}")
    except Exception as e:
        print(f"   Error: {e}")

    # Example 2: POST request with JSON
    print("\n‚ú® Example 2: POST Request")
    try:
        response = await fetch("https://jsonplaceholder.typicode.com/posts", {
            "method": "POST",
            "headers": {
                "Content-Type": "application/json"
            },
            "body": JSON.stringify({
                "title": "Nagari + Bun",
                "body": "Blazing fast HTTP requests!",
                "userId": 1
            })
        })

        if response.ok:
            data = await response.json()
            print(f"   Created post with ID: {data['id']}")
            print(f"   Title: {data['title']}")
            print("   ‚úì POST request successful!")
        else:
            print(f"   Error: {response.status}")
    except Exception as e:
        print(f"   Error: {e}")

    # Example 3: Parallel requests (Bun handles these efficiently)
    print("\n‚ú® Example 3: Parallel Requests")
    import time
    start_time = time.time()

    try:
        # Make 5 parallel requests
        urls = [
            "https://api.github.com/users/github",
            "https://api.github.com/users/microsoft",
            "https://api.github.com/users/google",
            "https://api.github.com/users/facebook",
            "https://api.github.com/users/netflix"
        ]

        # Fetch all in parallel
        promises = [fetch(url) for url in urls]
        responses = await Promise.all(promises)

        # Parse all responses
        data_promises = [r.json() for r in responses]
        users = await Promise.all(data_promises)

        end_time = time.time()
        elapsed = (end_time - start_time) * 1000

        print(f"   Fetched {len(users)} users in {elapsed:.2f}ms")
        for user in users:
            print(f"   ‚Ä¢ {user['login']}: {user['public_repos']} repos")

        print("   ‚úì Parallel requests completed!")
        print(f"   ‚ö° Bun's optimized fetch is blazing fast!")
    except Exception as e:
        print(f"   Error: {e}")

    # Example 4: Streaming response
    print("\n‚ú® Example 4: Streaming Response")
    try:
        response = await fetch("https://api.github.com/users/github")

        # Get response as text (streaming)
        text = await response.text()
        print(f"   Downloaded {len(text)} bytes")
        print("   ‚úì Streaming fetch successful!")
    except Exception as e:
        print(f"   Error: {e}")

    # Performance notes
    print("\n" + "=" * 50)
    print("üéâ Bun's Native Fetch Benefits:")
    print("   ‚Ä¢ Native implementation (no polyfills)")
    print("   ‚Ä¢ Faster than node-fetch or axios")
    print("   ‚Ä¢ Built-in HTTP/2 support")
    print("   ‚Ä¢ Automatic connection pooling")
    print("   ‚Ä¢ Optimized for parallel requests")
    print("\nüí° Nagari automatically uses Bun's fetch when available!")

# Main function
async def main():
    await fetch_example()

# Execute
if __name__ == "__main__":
    import asyncio
    asyncio.run(main())
